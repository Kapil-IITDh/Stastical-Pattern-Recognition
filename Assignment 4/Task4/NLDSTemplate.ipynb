{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Non Linear Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset while skipping the first line (meta-information)\n",
    "df = pd.read_csv(\"../Datasets/NonLinearDataset/NonLinearDataset.txt\", sep=\" \", header=None, skiprows=1)\n",
    "df = df.iloc[:, :2]  # Select only the first two columns (features)\n",
    "\n",
    "# Convert all values to numeric, coercing errors to NaN\n",
    "df = df.apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dividing training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign class labels based on the dataset structure\n",
    "# The first 500 examples belong to class 1, the next 500 to class 2, and the remaining 1000 to class 3\n",
    "df['class'] = np.concatenate([np.zeros(500), np.ones(500), np.full(1000, 2)])\n",
    "\n",
    "# Split the data into features (X) and labels (y)\n",
    "X = df.iloc[:, :2].values  # First two columns as features\n",
    "y = df['class'].values    # 'class' column as the target labels\n",
    "\n",
    "# Cast y to integer type to ensure correct processing\n",
    "y = y.astype(int)\n",
    "\n",
    "# Split into train and test data (70% training, 30% testing) based on the given order\n",
    "train_size = int(0.7 * len(df))\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "# Now we have the training and testing data, with three classes\n",
    "print(\"Training Data Shape:\", X_train.shape)\n",
    "print(\"Testing Data Shape:\", X_test.shape)\n",
    "print(\"Class Distribution in Training Data:\", np.bincount(y_train))\n",
    "print(\"Class Distribution in Testing Data:\", np.bincount(y_test))\n",
    "\n",
    "# Ensure all classes are represented in the train and test sets\n",
    "train_data_list = [X_train[y_train == i] for i in range(3)]\n",
    "test_data_list = [X_test[y_test == i] for i in range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.preprocessing import PolynomialFeatures  # Import for feature transformation\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read the dataset while skipping the first line (meta-information)\n",
    "df = pd.read_csv(\"../Datasets/NonLinearDataset/NonLinearDataset.txt\", sep=\" \", header=None, skiprows=1)\n",
    "df = df.iloc[:, :2]  # Select only the first two columns (features)\n",
    "\n",
    "# Convert all values to numeric, coercing errors to NaN\n",
    "df = df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Assign class labels based on the dataset structure\n",
    "df['class'] = np.concatenate([np.zeros(500), np.ones(500), np.full(1000, 2)])\n",
    "\n",
    "# Split the data into features (X) and labels (y)\n",
    "X = df.iloc[:, :2].values  # First two columns as features\n",
    "y = df['class'].values    # 'class' column as the target labels\n",
    "\n",
    "# Cast y to integer type to ensure correct processing\n",
    "y = y.astype(int)\n",
    "\n",
    "# Perform stratified split to ensure class distribution is maintained\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "\n",
    "# Debugging: print the class distribution in the training and testing sets\n",
    "print(\"Class Distribution in Training Data:\", np.bincount(y_train))\n",
    "print(\"Class Distribution in Testing Data:\", np.bincount(y_test))\n",
    "\n",
    "# Transform features using PolynomialFeatures\n",
    "poly = PolynomialFeatures(degree=3)  # Use polynomial features (degree 3, for example)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
